[tool.poetry]
name = "llama-cpp-python-server"
version = "0.1.0"
description = "llama-cpp-python server for GPU with CUDA"
authors = ["Ismail Bouajaja"]
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.12"
llama-cpp-python = {extras = ["server"], version = "^0.2.76"}


[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
